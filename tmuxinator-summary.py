#!/opt/homebrew/Caskroom/miniconda/base/bin/python
"""
Tmuxinator Project Summary - AI-Powered Analysis
Full-screen TUI application using Textual framework with OpenAI integration
"""

import os
import sys
import json
from datetime import date, datetime
from pathlib import Path
from typing import List, Optional
import yaml

from textual.app import App, ComposeResult
from textual.containers import Container, VerticalScroll
from textual.widgets import Static, Header, Footer, LoadingIndicator
from textual.binding import Binding
from textual import work
from rich.text import Text
from rich.markdown import Markdown

try:
    from openai import OpenAI
except ImportError:
    print("Error: openai package not installed", file=sys.stderr)
    print("Install with: /opt/homebrew/Caskroom/miniconda/base/bin/pip install openai", file=sys.stderr)
    sys.exit(1)


# ============================================================================
# Data Models
# ============================================================================

class ProjectWithProgress:
    """Represents a tmuxinator project with progress tracking"""

    def __init__(self, name: str, ddl: Optional[date], priority: str,
                 description: str, root: Optional[str], file_path: str):
        self.name = name
        self.ddl = ddl
        self.priority = priority.lower() if priority else "normal"
        self.description = description or ""
        self.root = root
        self.file_path = file_path
        self.progress_content = None

    def load_progress(self):
        """Load prgs.md content from project root"""
        if self.root and Path(self.root).exists():
            prgs_file = Path(self.root) / "prgs.md"
            if prgs_file.exists():
                try:
                    self.progress_content = prgs_file.read_text()
                except Exception as e:
                    self.progress_content = f"[Error reading prgs.md: {e}]"

    @property
    def days_left(self) -> Optional[int]:
        """Calculate days until deadline"""
        if not self.ddl:
            return None
        return (self.ddl - date.today()).days

    @property
    def is_overdue(self) -> bool:
        """Check if project is overdue"""
        return self.days_left is not None and self.days_left < 0

    @property
    def display_deadline(self) -> str:
        """Format deadline for display"""
        if not self.ddl:
            return "No deadline"
        days = self.days_left
        if days < 0:
            return f"OVERDUE by {abs(days)}d"
        elif days == 0:
            return "DUE TODAY"
        elif days <= 3:
            return f"URGENT ({days}d left)"
        elif days <= 7:
            return f"SOON ({days}d left)"
        else:
            return f"{days}d left"

    @property
    def deadline_color(self) -> str:
        """Get color for deadline display"""
        if not self.ddl:
            return "dim"
        days = self.days_left
        if days < 0 or days <= 3:
            return "red"
        elif days <= 7:
            return "yellow"
        else:
            return "green"

    @property
    def priority_display(self) -> str:
        """Get priority display text"""
        if self.priority in ["high", "urgent"]:
            return "[red bold][HIGH][/red bold]"
        elif self.priority == "low":
            return "[dim][LOW][/dim]"
        return ""


def load_projects(config_dir: Path) -> List[ProjectWithProgress]:
    """Load all tmuxinator projects from config directory"""
    projects = []

    if not config_dir.exists():
        return projects

    for yaml_file in config_dir.glob("*.yml"):
        # Skip template
        if yaml_file.name == "template.yml":
            continue

        try:
            with open(yaml_file, 'r') as f:
                config = yaml.safe_load(f)

            if not isinstance(config, dict):
                continue

            name = config.get('name', yaml_file.stem)
            ddl_str = config.get('ddl')
            priority = config.get('priority', 'normal')
            description = config.get('description', '')
            root = config.get('root')

            # Expand tilde in root path
            if root:
                root = os.path.expanduser(root)

            # Parse deadline
            ddl = None
            if ddl_str:
                try:
                    ddl = datetime.strptime(str(ddl_str), '%Y-%m-%d').date()
                except (ValueError, TypeError):
                    pass

            project = ProjectWithProgress(name, ddl, priority, description, root, str(yaml_file))
            project.load_progress()
            projects.append(project)

        except Exception as e:
            print(f"Warning: Failed to parse {yaml_file}: {e}", file=sys.stderr)

    # Sort: projects with ddl first (by date), then without ddl (by name)
    projects_with_ddl = [p for p in projects if p.ddl]
    projects_with_ddl.sort(key=lambda p: (p.ddl, p.name))

    projects_without_ddl = [p for p in projects if not p.ddl]
    projects_without_ddl.sort(key=lambda p: p.name)

    return projects_with_ddl + projects_without_ddl


# ============================================================================
# AI Analysis Engine
# ============================================================================

class AIAnalyzer:
    """Handles OpenAI API calls for project analysis"""

    def __init__(self):
        self.base_url = "https://api.chatanywhere.org/v1"
        self.api_key = os.environ.get("chat_any_where_key")
        # Use gpt-4o to avoid reasoning tokens (gpt-5.1 uses reasoning by default)
        self.model = "gpt-4o"

        # Cache directory
        self.cache_dir = Path.home() / ".cache" / "tmuxinator-summary"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / "ai_analysis.json"

    def load_cached_analysis(self) -> Optional[dict]:
        """Load cached AI analysis if exists"""
        if not self.cache_file.exists():
            return None

        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                # Check if cache is from today
                cache_date = cache_data.get('date')
                if cache_date == date.today().isoformat():
                    return {
                        "error": None,
                        "content": cache_data.get('content', '')
                    }
        except Exception:
            pass

        return None

    def save_analysis_to_cache(self, content: str):
        """Save AI analysis to cache"""
        try:
            cache_data = {
                'date': date.today().isoformat(),
                'content': content
            }
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
        except Exception:
            pass  # Silently fail if cache write fails

    def analyze_projects(self, projects: List[ProjectWithProgress], force: bool = False) -> dict:
        """Call OpenAI API to analyze projects and return recommendations"""
        # Try to load from cache if not forcing refresh
        if not force:
            cached = self.load_cached_analysis()
            if cached:
                return cached

        if not self.api_key:
            return {
                "error": "API key not found. Set $chat_any_where_key environment variable.",
                "content": ""
            }

        if not projects:
            return {
                "error": "No projects to analyze",
                "content": ""
            }

        prompt = self._build_prompt(projects)

        try:
            client = OpenAI(api_key=self.api_key, base_url=self.base_url)

            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªç”Ÿäº§åŠ›é¡¾é—®ï¼Œä¸“é—¨åˆ†æé¡¹ç›®ç»„åˆã€‚è¯·æä¾›ç®€æ´ã€å¯æ“ä½œçš„å»ºè®®ã€‚ç”¨ä¸­æ–‡å›å¤ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=1500  # Increased for more comprehensive analysis
            )

            content = response.choices[0].message.content

            # Debug logging to file
            with open("/tmp/ai-debug.log", "a") as f:
                f.write(f"\n=== API Response ===\n")
                f.write(f"Response message: {response.choices[0].message}\n")
                f.write(f"Content type: {type(content)}\n")
                f.write(f"Content: {content}\n")

            # Save to cache
            if content:
                self.save_analysis_to_cache(content)

            return {
                "error": None,
                "content": content
            }

        except Exception as e:
            return {
                "error": f"API call failed: {str(e)}",
                "content": ""
            }

    def _build_prompt(self, projects: List[ProjectWithProgress]) -> str:
        """Build the analysis prompt"""
        today = date.today()

        # Format project data
        project_summaries = []
        for p in projects:
            days_left = (p.ddl - today).days if p.ddl else None
            deadline_str = f"{days_left} days" if days_left is not None else "No deadline"

            progress = p.progress_content or "[No progress file]"
            # Truncate very long progress files
            if len(progress) > 500:
                progress = progress[:500] + "\n... [truncated]"

            project_summaries.append(f"""
Project: {p.name}
Deadline: {deadline_str}
Priority: {p.priority}
Description: {p.description}
Recent Progress:
{progress}
---
""")

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç”Ÿäº§åŠ›é¡¾é—®ï¼Œæ­£åœ¨åˆ†ææˆ‘çš„é¡¹ç›®ç»„åˆã€‚

ä»Šå¤©æ˜¯ {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã€‚

ä»¥ä¸‹æ˜¯æˆ‘çš„æ´»è·ƒé¡¹ç›®ï¼š

{''.join(project_summaries)}

è¯·åˆ†æå¹¶æä¾›ï¼š

1. **ä¼˜å…ˆçº§æ’åº**ï¼ˆæˆ‘åº”è¯¥ä¸“æ³¨çš„å‰3-5ä¸ªé¡¹ç›®ï¼‰ï¼š
   - æŒ‰ç…§æˆ‘åº”è¯¥ä¼˜å…ˆå¤„ç†çš„é¡ºåºæ’åˆ—é¡¹ç›®
   - å¯¹æ¯ä¸ªé¡¹ç›®è§£é‡Šä¸ºä»€ä¹ˆï¼ˆè€ƒè™‘ï¼šæˆªæ­¢æ—¥æœŸç´§è¿«æ€§ã€å½“å‰è¿›åº¦ã€ä¼˜å…ˆçº§çº§åˆ«ã€åŠ¨åŠ›ï¼‰

2. **æˆ˜ç•¥æ´å¯Ÿ**ï¼š
   - å“ªäº›é¡¹ç›®æœ‰é”™è¿‡æˆªæ­¢æ—¥æœŸçš„é£é™©ï¼Ÿ
   - å“ªäº›é‡è¦é¡¹ç›®ä¼¼ä¹åœæ»ä¸å‰ï¼Ÿ
   - å·¥ä½œè´Ÿè½½å¹³è¡¡æ˜¯å¦å­˜åœ¨é—®é¢˜ï¼ˆè¿‡äºåˆ†æ•£ vs è¿‡äºé›†ä¸­ï¼‰ï¼Ÿ
   - æœ¬å‘¨æ—¶é—´åˆ†é…å»ºè®®

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä½¿ç”¨ markdown æ ¼å¼ï¼Œç”¨ ## æ ‡é¢˜ã€‚
"""
        return prompt


# ============================================================================
# Textual Widgets
# ============================================================================

class AIRecommendationPanel(Static):
    """Panel displaying AI analysis results"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def show_empty(self):
        """Show initial empty state"""
        self.update("[dim italic]æŒ‰ 'a' é”®ä½¿ç”¨ AI åˆ†æé¡¹ç›®[/dim italic]")

    def show_analyzing(self):
        """Show analyzing state"""
        self.update("ğŸ”„ [yellow]æ­£åœ¨åˆ†æé¡¹ç›®...[/yellow]\n\nè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿã€‚")

    def show_results(self, content: str):
        """Show AI analysis results"""
        # Debug logging to file
        with open("/tmp/ai-debug.log", "a") as f:
            f.write(f"\n=== show_results ===\n")
            f.write(f"Content length: {len(content)}\n")
            f.write(f"Content: {content[:500]}\n")

        if not content:
            self.update("[red]Empty content received[/red]")
        else:
            # Try rendering as markdown
            try:
                self.update(Markdown(content))
                with open("/tmp/ai-debug.log", "a") as f:
                    f.write("Markdown render succeeded\n")
            except Exception as e:
                with open("/tmp/ai-debug.log", "a") as f:
                    f.write(f"Markdown render failed: {e}\n")
                # Fallback to plain text
                self.update(content)

    def show_error(self, error: str):
        """Show error message"""
        self.update(f"[red bold]é”™è¯¯ï¼š[/red bold] {error}\n\n[dim]æŒ‰ 'a' é”®é‡è¯•[/dim]")


class ProjectListPanel(Static):
    """Panel displaying project details"""

    def __init__(self, projects: List[ProjectWithProgress], *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.projects = projects

    def compose(self) -> ComposeResult:
        """Create the widget content"""
        if not self.projects:
            yield Static("[dim italic]æœªæ‰¾åˆ°é¡¹ç›®[/dim italic]")
            return

        content_parts = []

        for i, project in enumerate(self.projects):
            if i > 0:
                content_parts.append("\n")

            content_parts.append("â”€" * 80 + "\n")

            # Project name with priority
            name_line = f"[bold]{project.name}[/bold]"
            if project.priority_display:
                name_line += f" {project.priority_display}"
            content_parts.append(name_line + "\n")

            # Deadline
            ddl_text = project.display_deadline
            content_parts.append(f"æˆªæ­¢æ—¥æœŸ: [{project.deadline_color}]{ddl_text}[/{project.deadline_color}]\n")

            # Description
            if project.description:
                content_parts.append(f"æè¿°: {project.description}\n")

            # Root path
            if project.root:
                content_parts.append(f"è·¯å¾„: [dim]{project.root}[/dim]\n")

            content_parts.append("\n")

            # Progress
            if project.progress_content:
                content_parts.append("[bold]è¿›åº¦:[/bold]\n")
                # Indent progress content
                for line in project.progress_content.split('\n'):
                    content_parts.append(f"  {line}\n")
            else:
                content_parts.append("[dim][æœªæ‰¾åˆ° prgs.md][/dim]\n")

        yield Static("".join(content_parts))

    def refresh_projects(self, projects: List[ProjectWithProgress]):
        """Update with new project list"""
        self.projects = projects
        # Remove all children and recreate
        self.remove_children()
        self.mount(*self.compose())


# ============================================================================
# Main Application
# ============================================================================

class SummaryApp(App):
    """Tmuxinator Project Summary - AI-Powered Analysis"""

    CSS = """
    Screen {
        background: $surface;
    }

    #ai-scroll {
        height: 40%;
        border: heavy green;
        background: $success 5%;
    }

    #ai-panel {
        padding: 1;
    }

    #project-scroll {
        height: 60%;
        border: round $primary;
    }

    #project-panel {
        padding: 1;
    }

    Footer {
        background: $primary-background;
    }
    """

    BINDINGS = [
        Binding("q", "quit", "é€€å‡º", show=True),
        Binding("r", "refresh", "åˆ·æ–°", show=True),
        Binding("a", "analyze", "AIåˆ†æ", show=True),
        Binding("?", "help", "å¸®åŠ©", show=True),
    ]

    def __init__(self):
        super().__init__()
        self.title = "Tmuxinator é¡¹ç›®æ€»ç»“ - AI åˆ†æ"
        self.sub_title = f"{date.today().strftime('%Yå¹´%mæœˆ%dæ—¥')}"

        # Find config directory
        self.config_dir = Path.home() / ".config" / "tmuxinator"
        if not self.config_dir.exists():
            self.config_dir = Path.home() / ".tmuxinator"

        # Load projects
        self.projects = load_projects(self.config_dir)

        # AI analyzer
        self.ai_analyzer = AIAnalyzer()

        # Track if we've analyzed
        self.has_analyzed = False

    def on_mount(self) -> None:
        """Called when app is mounted - load cached analysis"""
        # Try to load cached analysis
        cached = self.ai_analyzer.load_cached_analysis()
        if cached and cached.get("content"):
            ai_panel = self.query_one("#ai-panel", AIRecommendationPanel)
            ai_panel.show_results(cached["content"])
            self.has_analyzed = True

    def compose(self) -> ComposeResult:
        """Create the application layout"""
        yield Header()

        # AI recommendations panel (scrollable)
        with VerticalScroll(id="ai-scroll") as ai_scroll:
            ai_scroll.border_title = "ğŸ¤– AI åˆ†æå»ºè®®"
            ai_panel = AIRecommendationPanel(id="ai-panel")
            ai_panel.show_empty()
            yield ai_panel

        # Project list panel (scrollable)
        with VerticalScroll(id="project-scroll") as project_scroll:
            project_scroll.border_title = f"ğŸ“‹ é¡¹ç›®è¯¦æƒ… ({len(self.projects)} ä¸ªé¡¹ç›®)"
            yield ProjectListPanel(self.projects, id="project-panel")

        yield Footer()

    def action_refresh(self) -> None:
        """Refresh projects from disk"""
        self.projects = load_projects(self.config_dir)

        # Update project panel
        project_panel = self.query_one("#project-panel", ProjectListPanel)
        project_panel.refresh_projects(self.projects)

        # Update project scroll container border title
        project_scroll = self.query_one("#project-scroll", VerticalScroll)
        project_scroll.border_title = f"ğŸ“‹ é¡¹ç›®è¯¦æƒ… ({len(self.projects)} ä¸ªé¡¹ç›®)"

        # Update subtitle
        self.sub_title = f"{date.today().strftime('%Y-%m-%d')} | {len(self.projects)} ä¸ªé¡¹ç›®"

        self.notify("é¡¹ç›®åˆ—è¡¨å·²åˆ·æ–°ï¼", severity="information")

    def action_analyze(self) -> None:
        """Analyze projects with AI"""
        ai_panel = self.query_one("#ai-panel", AIRecommendationPanel)

        # Show analyzing state
        ai_panel.show_analyzing()
        self.notify("æ­£åœ¨ä½¿ç”¨ AI åˆ†æé¡¹ç›®...", severity="information")

        # Run analysis in background worker to avoid blocking UI
        self.run_worker_analyze()

    @work(exclusive=True, thread=True)
    def run_worker_analyze(self) -> None:
        """Background worker for AI analysis"""
        # Call AI analyzer in worker thread with force=True to bypass cache
        result = self.ai_analyzer.analyze_projects(self.projects, force=True)

        # Update UI with results (safe to call from worker)
        self.call_from_thread(self.on_analysis_complete, result)

    def on_analysis_complete(self, result: dict) -> None:
        """Handle AI analysis results (called from main thread)"""
        ai_panel = self.query_one("#ai-panel", AIRecommendationPanel)

        # Debug logging to file
        with open("/tmp/ai-debug.log", "a") as f:
            f.write(f"\n=== on_analysis_complete ===\n")
            f.write(f"Result keys: {result.keys()}\n")
            f.write(f"Error: {result.get('error')}\n")
            f.write(f"Content length: {len(result.get('content', ''))}\n")
            f.write(f"Content preview: {result.get('content', '')[:500]}\n")

        if result["error"]:
            ai_panel.show_error(result["error"])
            self.notify(f"åˆ†æå¤±è´¥ï¼š{result['error']}", severity="error")
        else:
            content = result["content"]
            if not content or content.strip() == "":
                ai_panel.show_error("AI è¿”å›äº†ç©ºå“åº”")
                self.notify("AI è¿”å›äº†ç©ºå“åº”", severity="warning")
            else:
                ai_panel.show_results(content)
                self.notify("åˆ†æå®Œæˆï¼", severity="success")
                self.has_analyzed = True

    def action_help(self) -> None:
        """Show help message"""
        help_text = """
å¿«æ·é”®ï¼š
  a - ä½¿ç”¨ AI åˆ†æé¡¹ç›®
  r - ä»ç£ç›˜åˆ·æ–°é¡¹ç›®åˆ—è¡¨
  q - é€€å‡ºåº”ç”¨
  â†‘â†“ - æ»šåŠ¨é¢æ¿
  ? - æ˜¾ç¤ºæ­¤å¸®åŠ©
"""
        self.notify(help_text, severity="information", timeout=10)


# ============================================================================
# Entry Point
# ============================================================================

def main():
    """Main entry point"""
    app = SummaryApp()
    app.run()


if __name__ == "__main__":
    main()
